{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GridSearch Progress:   0%|          | 0/128 [00:00<?, ?it/s]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:02:42] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:   1%|          | 1/128 [00:12<26:40, 12.61s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:02:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:   2%|▏         | 2/128 [00:24<25:36, 12.19s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:03:07] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:   2%|▏         | 3/128 [00:36<25:38, 12.31s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:03:19] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:   3%|▎         | 4/128 [00:48<24:25, 11.82s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:03:30] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:   4%|▍         | 5/128 [01:00<24:55, 12.15s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:03:43] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:   5%|▍         | 6/128 [01:12<24:29, 12.05s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:03:55] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:   5%|▌         | 7/128 [01:24<24:30, 12.15s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:04:07] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:   6%|▋         | 8/128 [01:35<23:32, 11.77s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:04:18] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:   7%|▋         | 9/128 [01:58<29:57, 15.11s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:04:40] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:   8%|▊         | 10/128 [02:20<33:47, 17.18s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:05:02] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:   9%|▊         | 11/128 [02:43<37:01, 18.99s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:05:25] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:   9%|▉         | 12/128 [03:04<37:53, 19.60s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:05:46] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:  10%|█         | 13/128 [03:26<38:52, 20.28s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:06:08] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:  11%|█         | 14/128 [03:49<40:10, 21.15s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:06:31] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:  12%|█▏        | 15/128 [04:11<40:38, 21.58s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:06:54] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:  12%|█▎        | 16/128 [04:33<40:29, 21.69s/it]/home/harsh/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:07:16] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "GridSearch Progress:  12%|█▎        | 16/128 [04:45<33:19, 17.85s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 58\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m tqdm(param_combinations, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGridSearch Progress\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Create and train the model with the current set of parameters\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[1;32m     51\u001b[0m         objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     52\u001b[0m         eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m     57\u001b[0m     )\n\u001b[0;32m---> 58\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# Predict probabilities on validation set\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     y_val_pred_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Hackathons/Convolve/venv/lib/python3.12/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import dump\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the processed development dataset\n",
    "dev_data_path = \"/home/harsh/Hackathons/Convolve/data/dev/Dev_data_to_be_shared.csv\"\n",
    "data = pd.read_csv(dev_data_path)\n",
    "\n",
    "# Split data into features and target\n",
    "X = data.drop(columns=[\"bad_flag\", \"account_number\"])  # Exclude target and primary key\n",
    "y = data[\"bad_flag\"]\n",
    "\n",
    "# Split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Handle class imbalance using XGBoost's built-in scale_pos_weight\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"learning_rate\": [0.01, 0.1],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"reg_alpha\": [0, 0.1],\n",
    "    \"reg_lambda\": [1, 10]\n",
    "}\n",
    "\n",
    "# Convert parameter grid to explicit combinations\n",
    "param_combinations = list(ParameterGrid(param_grid))\n",
    "\n",
    "# Initialize variables to store the best model and score\n",
    "best_model = None\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "# Progress bar for hyperparameter tuning\n",
    "for params in tqdm(param_combinations, desc=\"GridSearch Progress\"):\n",
    "    # Create and train the model with the current set of parameters\n",
    "    model = XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        use_label_encoder=False,\n",
    "        random_state=42,\n",
    "        **params\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities on validation set\n",
    "    y_val_pred_prob = model.predict_proba(X_val)[:, 1]\n",
    "    auc = roc_auc_score(y_val, y_val_pred_prob)\n",
    "\n",
    "    # Update the best model if the current one is better\n",
    "    if auc > best_score:\n",
    "        best_model = model\n",
    "        best_score = auc\n",
    "        best_params = params\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best AUC-ROC Score: {best_score}\")\n",
    "\n",
    "# Save the best model\n",
    "dump(best_model, \"./home/harsh/Hackathons/Convolve/models/xgboost_best_model.pkl\")\n",
    "print(\"Best model saved!\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred_prob = best_model.predict_proba(X_val)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred_prob)\n",
    "print(f\"Validation AUC-ROC: {roc_auc}\")\n",
    "\n",
    "# Generate classification report and confusion matrix\n",
    "y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "xgb.plot_importance(best_model, max_num_features=15, importance_type=\"gain\")\n",
    "plt.title(\"Top 15 Feature Importances\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pycaret.classification import setup, compare_models, pull, save_model , predict_model\n",
    "\n",
    "# Load the processed development dataset\n",
    "dev_data_path = \"/home/harsh/Hackathons/Convolve/data/dev\"\n",
    "data = pd.read_csv(dev_data_path)\n",
    "\n",
    "# Quick overview of the dataset\n",
    "print(\"Dataset Overview:\")\n",
    "print(data.info())\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Describe dataset for basic stats\n",
    "stats = data.describe().T\n",
    "print(\"Dataset Statistics:\")\n",
    "print(stats)\n",
    "\n",
    "# PyCaret Setup\n",
    "# Define target and ignore primary key\n",
    "clf_setup = setup(\n",
    "    data=data,\n",
    "    target=\"bad_flag\",\n",
    "    ignore_features=[\"account_number\"],  # Primary key column\n",
    "    session_id=42,  # Ensure reproducibility\n",
    "    silent=True,\n",
    "    normalize=True,  # Normalize numerical features\n",
    "    feature_selection=True,  # Enable feature selection\n",
    "    fix_imbalance=True,  # Handle class imbalance\n",
    "    remove_multicollinearity=True,  # Remove correlated features\n",
    "    multicollinearity_threshold=0.9,  # Threshold for multicollinearity\n",
    "    use_gpu=True  # Use GPU for faster computation\n",
    ")\n",
    "\n",
    "# Compare models and select the best\n",
    "print(\"Training models and comparing performance...\")\n",
    "best_model = compare_models()\n",
    "\n",
    "# Retrieve and display all model performance metrics\n",
    "model_performance = pull()\n",
    "print(\"Model Performance Metrics:\")\n",
    "print(model_performance)\n",
    "\n",
    "# Save the best model\n",
    "save_model(best_model, \"/home/harsh/Hackathons/Convolve/models\")\n",
    "print(\"Best model saved!\")\n",
    "\n",
    "# Feature Importance\n",
    "from pycaret.utils import check_metric\n",
    "\n",
    "# Evaluate the best model on unseen data (optional)\n",
    "print(\"Evaluating the best model...\")\n",
    "predictions = predict_model(best_model)\n",
    "print(predictions.head())\n",
    "\n",
    "# Feature importance plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "feature_importance = best_model.feature_importances_  # Best model feature importance\n",
    "sns.barplot(x=feature_importance, y=data.drop(columns=[\"bad_flag\", \"account_number\"]).columns)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n",
    "\n",
    "# Save predictions for validation\n",
    "predictions[\"account_number\"] = data[\"account_number\"]  # Add back primary key\n",
    "predictions.to_csv(\"../outputs/predictions/validation_predictions.csv\", index=False)\n",
    "print(\"Predictions saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
